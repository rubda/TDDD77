\section{Teori}
Syftet med projektet är att ta fram ett snabbt och lättutvecklat program som löser konvexa kvadratiska optimeringsproblem. Det vi har gjort är att ha jämfört olika algoritmer mot varandra i fråga om hastighet, robusthet samt implementerbarhet. Problemet med detta är att algoritmerna som vi har testat varierar i hastighet beroende på hur stora matriserna som ska lösas är samt hur de är strukturerade, även vilket programmeringsspråk och plattform som algoritmen är implementerade på spelar roll.

\subsection{Liknande problem}
Det finns sedan tidigare redan många andra program som löser liknande optimeringsproblem. Anledning till att vi gör ett nytt är för att de som redan finns antingen är breda och riktar in sig på många olika problem, vilket gör dem långsammare eftersom de är sämre optimerade för just vårt problem. Ett annat är att de oftast inte är öppen källkod, vilket gör att man inte får med källkoden till programmet så att man själv inte kan vidareutveckla det. Ett annat problem med de som faktiskt har öppen källkod är att man inte säkert kan veta om de använder sig av tredjepartskod som har någon annan licens, eller om de utvecklare som varit med och skrivit koden skulle vilja ha ersättning för det de gjort.
Tanken med vårt program är att vi ska äga det, men Saab AB ska ha rätten att vidareutveckla och använda det kommersiellt.

\subsection{Algoritmer och metoder}
Vår huvudsakliga källa för de algoritmer och metoder vi använt kommer från boken Numerical Optimization av Jorge Nocedal och Stephen J. Wright. Denna bok var ett tips från vår kund eftersom den innehöll tre algoritmer som han tyckte skulle lämpa sig bäst för problemet. Det var sedan vårt jobb att välja den av dessa algoritmer som skulle vara snabbast, enklast att implementera och utveckla för vårt problem.
\\
När vi skulle välja lösningsalgoritm för konvexa kvadratiska problem fanns det två som var intressanta, Interior point method och Active set method. Metoderna återfinns i boken \emph{Numerical Optimization} och det var vår beställare Daniel som rekommenderade dessa. Enligt honom var båda ungefär lika komplicerade att implementera men trodde att ändå att Active set method kunde vara enklare. Detta och med tanke på att det fanns pseudokod för Active set-metoden i boken gjorde att vi tillslut valde att gå vidare med just Active set. 
\\
För att förstå hur vi skulle gå tillväga med att implementera Active set method, löste vi först problemet tillsammans för hand. Detta gjorde att vi fick en klarare bild av hur algoritmen skulle se ut och hur den kunde delas upp i mindre funktioner. Problem vi löste var ett väldigt litet problem (endast två variabler) för att det skulle gå att visualisera problemet på papper. \\
Något som vi märkte när problemet löstes för hand var att definitionen av hur subproblemet skulle lösas var tydlig och trivial när det löstes på papper, men att implementera metoden i kod var. 

\subsection{Active set method}   
Metoden har fått sitt namn efter att den iterativt väljer vilka bivillkor i optimeringsproblemet som ska vara aktiva och söker efter den mängd aktiva bivillkor som ger ett globalt minimum. Om man har läst någon kurs i optimering så märker man redan nu att den är väldigt lik Simplexmetoden, och det är för att Simplex är specialvariant av Active set. Skillnade är att Active set är mycket mer generell och kräver inte att man hela tiden står på något bivillkor. Detta gör att man även kan lösa kvadratiska optimeringsproblem istället för bara linjära. 


\subsection{Datastrukturer}
\subsubsection{Matriser}
\subsubsection{Working set}
\subsubsection{Problem}

\subsection{Startpunkt}
Att hitta en tillåten startpunkt är enligt boken ett lika svårt problem som optimeringsproblemet. Dock så fanns det flera olika metoder för att lösa detta problem. De som nämns i boken är '' Phase I'', ''Phase II'' och ''Big M'' som alla tre gör det de ska ganska fort. Problemet med dessa metoder är att de bygger på simplex. Om gruppen skulle välja att implementera någon av dessa skulle det betyda att även en simplexlösare skulle behöva implementeras. 

\subsubsection{Metod 1}
Till att börja med valdes en mer lättimplementerad lösning som inte fanns med i någon bok (som lästs). Denna metod byggde på att lösa många linjära system och leta efter en punkt där en delmängnd av bivillkoren är aktiva, men också att punkten även uppfyller alla andra bivillkor. Antalet kombinationer denna metod testar är då, räknat med $E$ st ''$=$''-bivillkor, $F$ st ''$\leq$''-bivillkor och $n$ st variabler:
$${F+(n-E) \choose (n-E)}, n>E $$
Detta sågs som relativt effektivt då gruppen trodde att $E \approx n-1$ alltid stämde. Men vid senare testdata visade det sig att så inte var fallet. I det test som fick metoden att falla var $F = 192, E = 62, n = 92$ vilket ledde till att oerhört många kombinationer skulle testas:
$${222 \choose 30} \approx 1.19*10^{37}$$
Vilket är ca 100 biljoner gånger antalet stjärnor i universum. Om man grovt antar att datorn kan testa runt en miljard kombinationer per sekund skulle det ta ca $4*10^{20}$ år för den att testa alla kombinationer, vilket är något varken vi eller kunden har tid för.

\subsubsection{Phase I}
Efter ytterliggare utbildning bestämdes det att ''Phase I'' skulle implementeras då denna metod ansågs lättast. ''Phase I'' och ''Phase II'' är egentligen bara simplexmetoden uppdelad i två separata steg där den första hittar en giltig punkt och den andra hittar en optimal. ''Phase I'' bygger på att man relaxerar problemet så att en en vald punkt är tillåten. I vårt fall väljs punkten alltid till origo eftersom det förenklar tänkandet och är den punkt som simplexmetoden vanligtvis utgår ifrån. Andra lösare, som till exempel MATLAB, låter en gissa på en startpunkt och låter en sedan utgå från den. Om gissningen är bra kan detta medföra att problemet blir lättare och går att lösa snabbare. Detta är givetvis inte nödvändigt och har därför inte implementerats. \\
Till att börja med skrivs alla bivillkor om så att de står på standardform, vilket ser ut enligt nedan.
$$Ex = h, \quad Fx \leq h$$
\raggedright där $E$ och $F$ är matriser innehållande $x$-variablernas koefficienter i bivillkoren. vektorerna $h$ och $g$ innehåller bivillkorens högerled. Ett krav är dessutom att alla element i $h$ måste vara positiva.
Vår kvadratiska problemlösare hanterar problem på formen:
$$Ex = h, \quad Fx \geq h$$
vilket innebär att både $F$ och $g$ måste multipliceras med $-1$ för att de ska vara på rätt form. För att uppfylla att $h$ är positiv måste de element däri som är negativa, och motsvarande rad i $E$-matrisen, multipliceras med $-1$.
När problemet sedan är på rätt form kan simplex-delen börja. \\
Först adderas en slackvariabel till varje ''$\leq$''-bivillkor för göra om dessa till ''$=$''-bivillkor precis som i vanliga simplexmetoden. Dessa nya variabler har blivit döpta till $s_i$ som slack. Bivillkoren till problemet ser nu ut på följande form:
$$Ex = h, \quad -Fx+Ds = -g$$
Där $D$ är matrisen innehållande $s$:s koefficienter i bivillkoren.
Sedan när alla slackvariabler är tillagda ska de virtuella variablerna läggas till, det är dessa variabler som relaxerar problemet. På varje bivillkor som var ett ''$=$''-bivillkor från början läggs en virtuell variabel på. Detta gör att villkoret nu passerar genom origo, alltså blir origo en giltig punkt. På alla bivillkor som var ''$\leq$''-bivillkor från början och som har negativt värde i högerledet (negativt värde i $g$-matrisen), läggs en negativ virtuell variabel på. Detta för att relaxera dessa så att punkten origo är giltig. På de som positivt värde i högerledet behövs inte detta. Anledningen till det är att slackvariablerna alltid måste vara positiva, vilket gör att i de bivillkoren, som har positivt högerled, är origo alltid är en giltig punkt. Bivillkoren ser nu ut på följande form:
$$Ex+Ca = h, \quad -Fx + Ds - Bv = g$$
Där $C$ och $B$ innehåller de virtuella variablernas koefficienter. \\ 
Simplexmetoden kräver också att alla variabler måste vara större/lika med noll, vilket är något inte speciellt ofta är uppfyllt i vårt fall. Därför måste varje variabel som kan vara negativ ersättas med två nya variabler, till exempel:
$$x_i = x_{i_1} - x_{i_2}$$
där $x_{i_1}\geq 0$ och $x_{i_2}\geq 0$ är uppfyllt. \\
Det enda som saknas nu är en målfunktion. Det som gör att punkten origo är giltig just nu är som sagt relaxationen av problemet, men om vi på något sätt kan stega oss fram med hjälp av simplexmetoden så att relaxationen försvinner så är punkten vi står i en giltig punkt för originalproblemet. Därför sätts målfunktionen till att minimera relaxationen, alltså minimera summan av de virtuella variablerna.
$$min z = \sum^i {v_i}, \quad  \Leftrightarrow \quad min z - \sum^i {v_i} = 0$$
Efter att ha satt in alla bivillkor i tablån är det sista som måste göras att eliminera alla virtuella variabler i målfunktion. Detta görs med hjälp av radoperationer i tablån, till exempel genom att addera en rad innehållande en virtuell variabel till målfunktionen. \\
Eftersom det är ett minimeringsproblem vill man iterera tills alla koefficienter i målfunktionen är negativa, Ta ut den mest positiva columnen i målfunktionen, och raden där kvoten av högerledet och elementet i vald kolumn är som minst. 



\subsection{Subproblem}
Till att börja med så är det som kallas ett ''Subproblem'' till Active set-metoden inget annat än ett annat optimeringsproblem. Dock skiljer sig det lite från huvudproblemet då det endast har ekvivalensbivillkor. Målfuntionens linjära termer skiljer sig också en aning då målfuntionens globala minimum har flyttats, relativt till position vi står i, för att det ska gå att ta ut en stegriktning som inte pekar rakt in i en vägg.
Som beskrivet tidigare kändes det ganska trivialt att lösa subproblemet, men efter en tid in i implementeringen upptäcktes det hur svårt det var att få datorn att göra samma sak som man så smidigt gjorde på papper. Det som krånglade till det var att på papper löste man ut variabler genom att derivera målfunktionen och använda sig av de linjära utryck som då kvarstår. Efter mycket slit utan resultat gick vi bort från den lösningsmetoden och påbörjade en ny utbildningsfas för att hitta en annan metod. Ur Numerical Optimization hittades dessa fyra: ''Range-space'', ''Null-space'', ''KKT'' och ''Conjugacy method''. ''Conjugacy method'' krävde att problemet var väldigt specifikt och såg ut på ett visst sätt, men de resterande tre var av intresse. Alla tre hade sina för- och nackdelar men alla uppfyllde i alla fall det som behövdes. Efter en del övervägningar landande till slut valet på ''Range-space'' som var överlägset lättaste att implementera. Nackdelen med metoden är dock att den kräver att man inverterar Q-matrisen (som innehåller de kvadratiska termerna i målfunktionen), vilket är en väldigt tung matematisk operation. Som tur är hade gruppen vetskap om att Q-matrisen alltid var symmetrisk samt att den oftast är näst intil diagonal. Detta gör att matrisen blir lättinverterbar, och det behövs endast göras en gång per algoritmkörning. Alltså blev kostnaden av valet av subproblemslösare inte så dyrt. Något som skullet vara trevligt skulle vara att jämföra de olika subproblemslösarna och se vilken som presterar bäst i olika fall.

\subsection{Vår lösning}
I figur 1 nedanför visas pseudokod för vår implementering av Active set method algoritmen från \emph{Numerical Optimization}.

\begin{algorithm}
\caption{Quadopt-solver}
\begin{algorithmic}
\Procedure{Quadopt-solver}{$problem$ $P$}
\If{$P$ has not feasible starting point $z_0$}
	\State Compute a feasible starting point $z_0$;
\EndIf	
\State Set $activeSet$ to be a subset of the active constraints at $z_0$ in $P$;
\While{$\textbf{true}$}
	\State Solve subproblem to find vector $p$ pointing towards the global minimum;
	\If{$p$ is zero vector}
		\If{$activeSet$ has zero constraints}
			\State \textbf{break};
		\EndIf		
		\If{Could not remove constraints from $P$}
			\State \textbf{break};
		\EndIf
	\Else
		\State Take step to better feasible point $z$ in $P$;
		\If{Could not step}
			\State \textbf{break};
		\EndIf
		\State Set $activeSet$ with new active constraints at $z$;	
	\EndIf
\EndWhile
\State  $solution$ in $P\gets z$;

\State \textbf{return} $solution$ in $P$;
	
\EndProcedure
\end{algorithmic}
\end{algorithm}



